# Application Settings
DEBUG=true

# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=7860
MCP_SERVER_URL=http://localhost:6789

# OpenAI Configuration (required for OpenAI backend)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=150

# Rate Limiting
RATE_LIMIT_REQUESTS=10
RATE_LIMIT_SECONDS=60

# Logging
LOG_LEVEL=INFO
LOG_FILE=app.log

# LLM Backend Configuration
# Set to 'openai' for ChatGPT, 'local' for local model, or 'gemini' for Google Gemini
LLM_BACKEND=openai

# Google Gemini Configuration
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_MODEL=gemini-1.5-flash
GEMINI_TEMPERATURE=0.7
GEMINI_MAX_TOKENS=2048

# Chat Configuration
DEFAULT_BACKEND=local  # 'openai' or 'local'
MAX_INPUT_LENGTH=1000
